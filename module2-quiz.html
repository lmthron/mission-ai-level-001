<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mission AI: Level 001 - Module 2 Checkpoint</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #1B365D 0%, #2a4a7a 100%);
            color: #333;
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 800px;
            margin: 0 auto;
            background: white;
            border-radius: 12px;
            box-shadow: 0 10px 40px rgba(0, 0, 0, 0.3);
            overflow: hidden;
        }

        .header {
            background: #1B365D;
            color: white;
            padding: 30px;
            text-align: center;
            border-bottom: 4px solid #7CB342;
        }

        .badge-icon {
            width: 80px;
            height: 80px;
            margin: 0 auto 15px;
            background: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 36px;
            border: 3px solid #4A90E2;
        }

        h1 {
            font-size: 28px;
            margin-bottom: 5px;
            letter-spacing: 1px;
        }

        .subtitle {
            color: #4A90E2;
            font-size: 16px;
            font-weight: normal;
        }

        .content {
            padding: 40px;
        }

        .intro {
            text-align: center;
            margin-bottom: 30px;
            color: #666;
            line-height: 1.6;
        }

        .question-container {
            display: none;
            animation: fadeIn 0.3s ease-in;
        }

        .question-container.active {
            display: block;
        }

        @keyframes fadeIn {
            from { opacity: 0; transform: translateY(10px); }
            to { opacity: 1; transform: translateY(0); }
        }

        .question-number {
            color: #4A90E2;
            font-weight: bold;
            font-size: 14px;
            margin-bottom: 10px;
        }

        .question {
            font-size: 20px;
            font-weight: 600;
            color: #1B365D;
            margin-bottom: 25px;
            line-height: 1.4;
        }

        .options {
            display: flex;
            flex-direction: column;
            gap: 12px;
        }

        .option {
            background: #f8f9fa;
            border: 2px solid #e0e0e0;
            border-radius: 8px;
            padding: 18px;
            cursor: pointer;
            transition: all 0.2s ease;
            display: flex;
            align-items: center;
            gap: 12px;
        }

        .option:hover {
            border-color: #4A90E2;
            background: #f0f7ff;
            transform: translateX(5px);
        }

        .option.selected {
            border-color: #4A90E2;
            background: #e3f2fd;
        }

        .option.correct {
            border-color: #7CB342;
            background: #f1f8e9;
        }

        .option.incorrect {
            border-color: #e53935;
            background: #ffebee;
        }

        .option-letter {
            width: 32px;
            height: 32px;
            background: #4A90E2;
            color: white;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-weight: bold;
            flex-shrink: 0;
        }

        .option.correct .option-letter {
            background: #7CB342;
        }

        .option.incorrect .option-letter {
            background: #e53935;
        }

        .feedback {
            margin-top: 20px;
            padding: 15px;
            border-radius: 8px;
            display: none;
            line-height: 1.6;
        }

        .feedback.show {
            display: block;
            animation: fadeIn 0.3s ease-in;
        }

        .feedback.correct {
            background: #f1f8e9;
            border-left: 4px solid #7CB342;
            color: #33691e;
        }

        .feedback.incorrect {
            background: #ffebee;
            border-left: 4px solid #e53935;
            color: #b71c1c;
        }

        .nav-buttons {
            display: flex;
            justify-content: space-between;
            margin-top: 30px;
            gap: 15px;
        }

        button {
            padding: 14px 30px;
            border: none;
            border-radius: 8px;
            font-size: 16px;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.2s ease;
        }

        .btn-primary {
            background: #4A90E2;
            color: white;
            flex: 1;
        }

        .btn-primary:hover:not(:disabled) {
            background: #357abd;
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(74, 144, 226, 0.4);
        }

        .btn-secondary {
            background: #e0e0e0;
            color: #666;
        }

        .btn-secondary:hover:not(:disabled) {
            background: #bdbdbd;
        }

        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }

        .results {
            display: none;
            text-align: center;
        }

        .results.show {
            display: block;
            animation: fadeIn 0.5s ease-in;
        }

        .score-circle {
            width: 200px;
            height: 200px;
            margin: 30px auto;
            border-radius: 50%;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            font-size: 48px;
            font-weight: bold;
            color: white;
        }

        .score-circle.pass {
            background: linear-gradient(135deg, #7CB342, #9ccc65);
            box-shadow: 0 8px 24px rgba(124, 179, 66, 0.4);
        }

        .score-circle.fail {
            background: linear-gradient(135deg, #e53935, #ef5350);
            box-shadow: 0 8px 24px rgba(229, 57, 53, 0.4);
        }

        .score-label {
            font-size: 16px;
            margin-top: 8px;
            opacity: 0.9;
        }

        .result-message {
            font-size: 24px;
            font-weight: bold;
            color: #1B365D;
            margin: 20px 0;
        }

        .result-details {
            background: #f8f9fa;
            border-radius: 8px;
            padding: 20px;
            margin: 20px 0;
            text-align: left;
        }

        .result-item {
            display: flex;
            justify-content: space-between;
            padding: 10px 0;
            border-bottom: 1px solid #e0e0e0;
        }

        .result-item:last-child {
            border-bottom: none;
        }

        .badge-earned {
            margin: 30px 0;
            padding: 25px;
            background: linear-gradient(135deg, #1B365D, #2a4a7a);
            border-radius: 12px;
            color: white;
        }

        .badge-earned h3 {
            margin-bottom: 10px;
            color: #7CB342;
        }

        .start-screen {
            text-align: center;
        }

        .start-screen h2 {
            color: #1B365D;
            font-size: 24px;
            margin: 20px 0;
        }

        .mission-brief {
            background: #f8f9fa;
            border-left: 4px solid #4A90E2;
            padding: 20px;
            margin: 30px 0;
            text-align: left;
            border-radius: 4px;
            line-height: 1.8;
        }

        .mission-brief strong {
            color: #1B365D;
        }

        .progress-bar {
            height: 6px;
            background: #e0e0e0;
            border-radius: 3px;
            margin-bottom: 30px;
            overflow: hidden;
        }

        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, #4A90E2, #7CB342);
            transition: width 0.3s ease;
        }

        @media (max-width: 600px) {
            .content {
                padding: 20px;
            }
            
            h1 {
                font-size: 22px;
            }
            
            .question {
                font-size: 18px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <div class="badge-icon">üéØ</div>
            <h1>MISSION AI: LEVEL 001</h1>
            <p class="subtitle">Module 2 Checkpoint Quiz</p>
        </div>

        <div class="content">
            <div id="startScreen" class="start-screen">
                <h2>Agent, Your Next Mission Awaits</h2>
                <p class="intro">
                    You've learned the anatomy of a good prompt. Now it's time to prove you can write prompts that get results.
                    This checkpoint will test your understanding of the four-element framework.
                </p>
                
                <div class="mission-brief">
                    <strong>Mission Briefing:</strong><br>
                    ‚Ä¢ 10 questions covering prompt engineering fundamentals<br>
                    ‚Ä¢ Focus on the four elements: Context, Specificity, Constraints, Format<br>
                    ‚Ä¢ You must score 90% or higher to pass<br>
                    ‚Ä¢ You can retake the quiz if needed<br>
                    ‚Ä¢ Apply what you've learned to real scenarios
                </div>

                <button class="btn-primary" onclick="startQuiz()">BEGIN MISSION</button>
            </div>

            <div id="quizArea" style="display: none;">
                <div class="progress-bar">
                    <div class="progress-fill" id="progressBar"></div>
                </div>

                <div id="questionsContainer"></div>

                <div class="nav-buttons">
                    <button class="btn-secondary" id="prevBtn" onclick="previousQuestion()" disabled>Previous</button>
                    <button class="btn-primary" id="nextBtn" onclick="nextQuestion()" disabled>Next Question</button>
                </div>
            </div>

            <div id="results" class="results">
                <div id="scoreCircle" class="score-circle">
                    <div>
                        <span id="scorePercent">0</span>%
                        <div class="score-label">MISSION SCORE</div>
                    </div>
                </div>
                
                <div class="result-message" id="resultMessage"></div>
                
                <div class="result-details">
                    <div class="result-item">
                        <span>Questions Correct:</span>
                        <strong id="correctCount">0</strong>
                    </div>
                    <div class="result-item">
                        <span>Total Questions:</span>
                        <strong id="totalCount">0</strong>
                    </div>
                    <div class="result-item">
                        <span>Pass Threshold:</span>
                        <strong>90%</strong>
                    </div>
                </div>

                <div id="badgeSection"></div>

                <button class="btn-primary" onclick="resetQuiz()">Retake Mission</button>
            </div>
        </div>
    </div>

    <script>
        const quizData = [
            {
                question: "According to Module 2, what are the FOUR key elements of a good prompt?",
                options: [
                    "Purpose, Audience, Tone, Structure",
                    "Length, Detail, Format, Examples",
                    "Context, Specificity, Constraints, Format",
                    "Question, Background, Requirements, Output"
                ],
                correct: 2,
                feedback: {
                    correct: "Perfect! The four elements are Context, Specificity, Constraints, and Format. These are the foundation of effective prompts.",
                    incorrect: "Review Part 2 of the module. The four key elements are: Context (situation/audience), Specificity (exactly what you want), Constraints (what to include/avoid), and Format (how to structure output)."
                }
            },
            {
                question: "What does the 'Context' element of a prompt provide to AI?",
                options: [
                    "The exact words to use in the response",
                    "The situation, audience, and purpose so AI understands your request",
                    "The length and format of the desired output",
                    "Examples of what not to include"
                ],
                correct: 1,
                feedback: {
                    correct: "Exactly! Context tells AI what it needs to know about the situation, audience, and purpose so it can tailor its response appropriately.",
                    incorrect: "Context is about giving AI the background it needs. From the module: 'What's the situation? Who's the audience? What's the purpose?' AI doesn't know your context, so you need to provide it."
                }
            },
            {
                question: "Which prompt demonstrates good use of the 'Specificity' element?",
                options: [
                    "Summarize this report for me",
                    "Summarize this 10-page report into 5 bullet points, focusing on key findings and recommendations",
                    "Create a summary of this report that highlights the important parts",
                    "Give me a brief summary that's easy to read"
                ],
                correct: 1,
                feedback: {
                    correct: "Perfect! This prompt is specific about what to do (summarize), how much content (10 pages to 5 bullets), what to focus on (key findings and recommendations), and the exact format.",
                    incorrect: "Specificity means being clear about exactly what you want. The correct answer specifies: the action (summarize), the input (10-page report), the output format (5 bullet points), AND the focus (key findings and recommendations). The other options seem specific but are vague about format, length, or focus areas."
                }
            },
            {
                question: "What is the purpose of the 'Constraints' element in a prompt?",
                options: [
                    "To prevent AI from using certain words",
                    "To restrict AI to only one type of response",
                    "To limit how long the AI can think about the answer",
                    "To tell AI what to include or avoid so it doesn't make wrong assumptions"
                ],
                correct: 3,
                feedback: {
                    correct: "Correct! Constraints set boundaries by telling AI what should be included and what should be avoided. This prevents AI from making assumptions.",
                    incorrect: "From the module: 'AI will make assumptions if you don't set boundaries. Tell it what to include and what to skip.' Constraints guide AI's decision-making about content."
                }
            },
            {
                question: "Why does specifying 'Format' matter in a prompt?",
                options: [
                    "AI can only respond in certain formats",
                    "The right format makes information immediately useful for your purpose",
                    "It makes the AI work faster",
                    "It's optional and doesn't really impact results"
                ],
                correct: 1,
                feedback: {
                    correct: "Exactly! The module states: 'The right format makes information immediately useful.' Specifying structure, length, and style ensures you get output you can actually use.",
                    incorrect: "Format is critical. The module explains: 'The right format makes information immediately useful. Specify structure, length, and style.' Without format specifications, AI might give you a paragraph when you needed a table, or vice versa."
                }
            },
            {
                question: "What is the main difference between 'Write an email about the delay' and 'Write an email to a customer explaining their order will be delayed by 3 days due to a supplier issue'?",
                options: [
                    "The first one allows AI more creative freedom to write a better email",
                    "The second one specifies the email format more clearly",
                    "The second one includes the tone and audience, while the first doesn't specify format",
                    "The second one provides context and specificity so AI knows the situation and exactly what to address"
                ],
                correct: 3,
                feedback: {
                    correct: "Perfect! The second prompt gives AI the context (customer email, supplier issue) and specificity (3-day delay, reason) needed to write a targeted, useful response.",
                    incorrect: "This example from the module shows why context and specificity matter together. The first prompt is vague - AI doesn't know who the email is for, why there's a delay, or what information to include. The second prompt provides context (customer, supplier issue) AND specificity (3 days, what to explain). Neither prompt specifies format or tone explicitly, and 'creative freedom' isn't the issue - AI needs direction."
                }
            },
            {
                question: "According to Module 2, what should you do if AI gives you a response that isn't quite right?",
                options: [
                    "Refine it by telling AI specifically what to fix or change in the current response",
                    "Try the same prompt in a different AI tool to see if it works better",
                    "Simplify your prompt by removing details since AI seems confused by complexity",
                    "Start with a fresh conversation and rewrite your entire prompt from scratch"
                ],
                correct: 0,
                feedback: {
                    correct: "Exactly! Exercise 2 taught you to iterate: 'AI is a tool you shape through feedback. Don't accept the first output - refine it.' Tell AI specifically what needs to change like 'This is too formal. Make it more conversational.'",
                    incorrect: "The module emphasizes iteration in Exercise 2: 'AI rarely gets it perfect on the first try. Learn to refine.' You don't need to start over or switch tools - just tell AI what to fix: 'This is too formal. Make it more conversational' or 'Add a section about next steps.' Iteration in the same conversation is more efficient than starting fresh."
                }
            },
            {
                question: "Which of these is a common prompting mistake identified in Module 2?",
                options: [
                    "Providing context about your audience when AI should figure that out itself",
                    "Including too many specific details that constrain AI's creativity",
                    "Asking for everything at once in a single complex prompt instead of breaking it into steps",
                    "Using the four-element framework rigidly instead of adapting to each situation"
                ],
                correct: 2,
                feedback: {
                    correct: "Correct! The module identifies this as Mistake #1: Asking for everything at once. Better approach: Break it into steps - first get a draft, then refine it.",
                    incorrect: "Review Part 5 on Common Prompting Mistakes. The module shows that asking for everything at once (like 'Write me an email that's professional but friendly and explains the situation but doesn't go into too much detail...') is a mistake. Break complex requests into steps instead. More specificity and context are helpful, not harmful."
                }
            },
            {
                question: "What does Module 2 teach about providing examples in your prompts?",
                options: [
                    "AI learns your preferences over time so examples become less necessary with use",
                    "Examples work well for creative tasks but aren't needed for analytical work",
                    "Save examples for follow-up prompts rather than including them initially",
                    "Show what you mean by subjective terms like 'nicely' or 'professional' - examples clarify expectations"
                ],
                correct: 3,
                feedback: {
                    correct: "Perfect! The module shows that vague terms like 'format this data nicely' need examples. Better: 'Format this data as a table with columns for Name, Amount, and Date.'",
                    incorrect: "The module addresses this as Mistake #2: Not providing examples. Words like 'nicely,' 'professional,' or 'briefly' mean different things to different people. Show AI what you mean with specific examples or descriptions. Examples help with any type of task, and AI doesn't remember preferences across conversations."
                }
            },
            {
                question: "According to Module 2, if AI gives you 'garbage' output, what does this usually mean?",
                options: [
                    "You need to provide more examples of the exact output format you want",
                    "Your prompt probably wasn't clear enough - refine it and try again",
                    "The AI model you're using isn't sophisticated enough for your request",
                    "Your request is too complex or unusual for current AI capabilities"
                ],
                correct: 1,
                feedback: {
                    correct: "Exactly right! The module states: 'If AI gives you garbage, your prompt probably wasn't clear enough. Don't give up - refine and try again.' The issue is usually the prompt, not the AI.",
                    incorrect: "The module addresses this as Mistake #4: Giving up after bad output. 'If AI gives you garbage, your prompt probably wasn't clear enough. Don't give up - refine and try again.' Bad output usually means your prompt needs improvement - more context, clearer specificity, better constraints, or format guidance. Don't assume the AI can't handle it."
                }
            }
        ];

        let currentQuestion = 0;
        let userAnswers = [];
        let score = 0;

        function startQuiz() {
            document.getElementById('startScreen').style.display = 'none';
            document.getElementById('quizArea').style.display = 'block';
            renderQuestions();
            showQuestion(0);
            updateProgress();
        }

        function renderQuestions() {
            const container = document.getElementById('questionsContainer');
            container.innerHTML = '';

            quizData.forEach((q, index) => {
                const questionDiv = document.createElement('div');
                questionDiv.className = 'question-container';
                questionDiv.id = `question-${index}`;
                
                const optionsHTML = q.options.map((option, optIndex) => `
                    <div class="option" onclick="selectAnswer(${index}, ${optIndex})">
                        <span class="option-letter">${String.fromCharCode(65 + optIndex)}</span>
                        <span>${option}</span>
                    </div>
                `).join('');

                questionDiv.innerHTML = `
                    <div class="question-number">Question ${index + 1} of ${quizData.length}</div>
                    <div class="question">${q.question}</div>
                    <div class="options" id="options-${index}">
                        ${optionsHTML}
                    </div>
                    <div class="feedback" id="feedback-${index}"></div>
                `;

                container.appendChild(questionDiv);
            });
        }

        function showQuestion(index) {
            document.querySelectorAll('.question-container').forEach(q => q.classList.remove('active'));
            document.getElementById(`question-${index}`).classList.add('active');
            
            currentQuestion = index;
            updateButtons();
            updateProgress();
        }

        function selectAnswer(questionIndex, answerIndex) {
            if (userAnswers[questionIndex] !== undefined) return;

            userAnswers[questionIndex] = answerIndex;
            
            const optionsContainer = document.getElementById(`options-${questionIndex}`);
            const options = optionsContainer.querySelectorAll('.option');
            const feedbackDiv = document.getElementById(`feedback-${questionIndex}`);
            
            const isCorrect = answerIndex === quizData[questionIndex].correct;
            
            options.forEach((option, idx) => {
                if (idx === quizData[questionIndex].correct) {
                    option.classList.add('correct');
                } else if (idx === answerIndex) {
                    option.classList.add('incorrect');
                }
                option.style.pointerEvents = 'none';
            });

            feedbackDiv.className = `feedback show ${isCorrect ? 'correct' : 'incorrect'}`;
            feedbackDiv.innerHTML = isCorrect ? 
                `‚úì ${quizData[questionIndex].feedback.correct}` : 
                `‚úó ${quizData[questionIndex].feedback.incorrect}`;

            if (isCorrect) score++;
            
            updateButtons();
        }

        function updateButtons() {
            const prevBtn = document.getElementById('prevBtn');
            const nextBtn = document.getElementById('nextBtn');
            
            prevBtn.disabled = currentQuestion === 0;
            
            if (currentQuestion === quizData.length - 1) {
                if (userAnswers[currentQuestion] !== undefined) {
                    nextBtn.textContent = 'View Results';
                    nextBtn.disabled = false;
                } else {
                    nextBtn.textContent = 'View Results';
                    nextBtn.disabled = true;
                }
            } else {
                nextBtn.textContent = 'Next Question';
                nextBtn.disabled = userAnswers[currentQuestion] === undefined;
            }
        }

        function nextQuestion() {
            if (currentQuestion < quizData.length - 1) {
                showQuestion(currentQuestion + 1);
            } else {
                showResults();
            }
        }

        function previousQuestion() {
            if (currentQuestion > 0) {
                showQuestion(currentQuestion - 1);
            }
        }

        function updateProgress() {
            const progress = ((currentQuestion + 1) / quizData.length) * 100;
            document.getElementById('progressBar').style.width = progress + '%';
        }

        function showResults() {
            document.getElementById('quizArea').style.display = 'none';
            document.getElementById('results').classList.add('show');
            
            const percentage = Math.round((score / quizData.length) * 100);
            const passed = percentage >= 90;
            
            document.getElementById('scorePercent').textContent = percentage;
            document.getElementById('correctCount').textContent = score;
            document.getElementById('totalCount').textContent = quizData.length;
            
            const scoreCircle = document.getElementById('scoreCircle');
            scoreCircle.className = `score-circle ${passed ? 'pass' : 'fail'}`;
            
            const resultMessage = document.getElementById('resultMessage');
            const badgeSection = document.getElementById('badgeSection');
            
            if (passed) {
                resultMessage.textContent = 'üéâ Mission Complete!';
                badgeSection.innerHTML = `
                    <div class="badge-earned">
                        <h3>üèÖ FIELD OPERATIVE STATUS EARNED</h3>
                        <p>Outstanding work, Agent! You've mastered the art of prompt engineering and demonstrated your ability to write prompts that get results. You've earned the Field Operative badge and are cleared to proceed to Module 3.</p>
                    </div>
                `;
            } else {
                resultMessage.textContent = 'Mission Incomplete';
                badgeSection.innerHTML = `
                    <div class="badge-earned" style="background: linear-gradient(135deg, #e53935, #ef5350);">
                        <h3>üìö Additional Training Required</h3>
                        <p>You need 90% or higher to pass. Review Module 2 and focus on the four-element framework: Context, Specificity, Constraints, and Format. Study the before/after examples and practice transforming vague prompts into specific ones!</p>
                    </div>
                `;
            }
        }

        function resetQuiz() {
            currentQuestion = 0;
            userAnswers = [];
            score = 0;
            
            document.getElementById('results').classList.remove('show');
            document.getElementById('startScreen').style.display = 'block';
        }
    </script>
</body>
</html>
